# Build, Train, and Deploy ML Pipelines using BERT

## Overview

This repository contains code and instructions for building, training, and deploying a BERT-Based text classifier using Amazon SageMaker Pipelines.

## Prerequisites

- AWS account with appropriate permissions.
- Python 3.7 or later.
- AWS Command Line Interface (CLI).
- Amazon SageMaker Python SDK.

## Project Structure

- `src/`: Contains the source code for data preprocessing and model training.
- `prepare_data.py`: Script for data preprocessing.
- `train_model.py`: Script for model training.

## Getting Started

1. Clone this repository:

```bash
git clone https://github.com/gyasifred/Build-Train-and-Deploy-ML-Pipelines-using-BERT.git
cd Build-Train-and-Deploy-ML-Pipelines-using-BERT
```

2. Install required packages:

3. Configure AWS credentials:

4. Update parameters in the code.

5. Run the notebook/script to create and execute the SageMaker Pipeline.

## Usage

1. Follow instructions in the lab notebook.

2. Monitor pipeline execution and review results.

3. Deploy the trained model as a REST endpoint.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

Based on Amazon SageMaker Pipelines example and uses SageMaker Python SDK.
